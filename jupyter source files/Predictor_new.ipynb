{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30987ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet50 , preprocess_input , decode_predictions\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model , Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0cb98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model_weights/model_11.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4a31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp  = ResNet50(weights = \"imagenet\" , input_shape = (224 , 224 , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5672bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = Model(model_temp.input , model_temp.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c90270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c805ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    img = image.load_img(img , target_size = (224 , 224 , 3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img , axis = 0)\n",
    "    # Normalisation \n",
    "    img = preprocess_input(img)  # Resnet model takes images in this format\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f10fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_img(img):\n",
    "    img = preprocess_img(img)\n",
    "    feature_vector = model_resnet.predict(img)\n",
    "    feature_vector = feature_vector.reshape((1 , feature_vector.shape[1] ))\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d683cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = encode_img('sample_img_down.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1c0241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805d31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_to_idx = joblib.load('./word_to_idx')\n",
    "idx_to_word = joblib.load('./idx_to_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a95a7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_caption(photo):\n",
    "    in_text = \"startseq\"\n",
    "    maxlen = 35\n",
    "    for i in range(maxlen):\n",
    "        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
    "        sequence = pad_sequences([sequence] , maxlen = maxlen , padding = 'post')\n",
    "        \n",
    "        ypred = model.predict([photo , sequence])\n",
    "        ypred = np.argmax(ypred)\n",
    "        \n",
    "        word = idx_to_word[ypred]\n",
    "        in_text = in_text +' '+  word\n",
    "        \n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "    final_caption = in_text.split()[1:-1]        \n",
    "    final_caption = \" \".join(final_caption)\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec627b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0235ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a787d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'man and woman are sitting on the edge of the river'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_caption(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc57310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
